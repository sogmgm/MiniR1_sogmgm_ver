# Mini-R1: DeepSeek R1 "Aha Moment" Reproduction

**ë‹¨ì¼ GPU** RunPod í™˜ê²½ì—ì„œ ê²½ëŸ‰í™”ëœ GRPO í•™ìŠµìœ¼ë¡œ DeepSeek R1ì˜ ì¶”ë¡  ëŠ¥ë ¥ ì¬í˜„

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ ë° ì‹œìŠ¤í…œ ì‚¬ì–‘

### í•µì‹¬ ê¸°ìˆ 
- **íŒ¨í‚¤ì§€ ê´€ë¦¬**: UV (ë¹ ë¥¸ Python íŒ¨í‚¤ì§€ ê´€ë¦¬ì)
- **ëª¨ë¸**: Qwen2.5-1.5B/3B-Instruct (ë©”ëª¨ë¦¬ íš¨ìœ¨í™”)
- **í•™ìŠµ ë°©ë²•**: GRPO (Group Relative Policy Optimization)
- **í™˜ê²½**: **ë‹¨ì¼ GPU** (Multi-GPU ì§€ì› ì—†ìŒ)


**ì‹¤ìŠµ í™˜ê²½ ì°¸ê³ **: NVIDIA A100 80GB ë‹¨ì¼ GPU ê¸°ì¤€ìœ¼ë¡œ ì•½ 10~12ì‹œê°„ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ“¦ í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´
- Python 3.10+
- CUDA 12.1+
- UV íŒ¨í‚¤ì§€ ê´€ë¦¬ì
- 50GB ì´ìƒ ë””ìŠ¤í¬ ê³µê°„

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
MiniR1/
â”œâ”€â”€ README.md                    # ğŸ“– í”„ë¡œì íŠ¸ ì „ì²´ ê°€ì´ë“œ (ì´ ë¬¸ì„œ)
â”œâ”€â”€ RUNPOD_SETUP.md              # ğŸš€ RunPod ì™„ì „ ê°€ì´ë“œ (ì„¤ì¹˜+ì‹¤í–‰+ë¬¸ì œí•´ê²°)
â”œâ”€â”€ TENSORBOARD_GUIDE.md         # ğŸ“Š TensorBoard ì‚¬ìš©ë²•
â”œâ”€â”€ PROGRESS.md                  # ğŸ“ ê°œë°œ ì§„í–‰ ìƒí™© ê¸°ë¡
â”œâ”€â”€ pyproject.toml               # ğŸ“¦ UV íŒ¨í‚¤ì§€ ì„¤ì • ë° ì˜ì¡´ì„±
â”‚
â”œâ”€â”€ configs/                     # âš™ï¸ ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ training_config.yaml     #    í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ëª¨ë¸, ë°°ì¹˜, GRPO ë“±)
â”‚
â”œâ”€â”€ scripts/                     # ğŸ› ï¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ dataset_prep.py          #    ë°ì´í„°ì…‹ ì¤€ë¹„ (HF â†’ R1 í˜•ì‹ ë³€í™˜)
â”‚   â”œâ”€â”€ rewards.py               #    í˜•ì‹/ìˆ˜ì‹/ê¸¸ì´ ë³´ìƒ + ì•ˆì „í•œ ìˆ˜ì‹ í‰ê°€
â”‚   â”œâ”€â”€ train_grpo.py            #    ê°€ì¤‘ì¹˜ ë³´ìƒ ì ìš© GRPO í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ evaluate.py              #    ëª¨ë¸ í‰ê°€ ë° í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ check_environment.py     #    í™˜ê²½ ì„¤ì • í™•ì¸
â”‚
â”œâ”€â”€ notebooks/                   # ğŸ““ Jupyter ë…¸íŠ¸ë¶
â”‚   â””â”€â”€ data_exploration.ipynb   #    ë°ì´í„° íƒìƒ‰ ë° ì‹¤í—˜
â”‚
â”œâ”€â”€ .cache/                      # ğŸ’¾ ìºì‹œ ë””ë ‰í† ë¦¬ (ìƒì„±ë¨)
â”‚   â””â”€â”€ datasets/                #    ì¤€ë¹„ëœ ë°ì´í„°ì…‹ ì €ì¥
â”‚       â”œâ”€â”€ train_countdown_r1.json      # í•™ìŠµ ë°ì´í„° (3,600 ìƒ˜í”Œ)
â”‚       â”œâ”€â”€ test_countdown_r1.json       # í…ŒìŠ¤íŠ¸ ë°ì´í„° (400 ìƒ˜í”Œ)
â”‚       â””â”€â”€ dataset_metadata.json        # ë°ì´í„°ì…‹ ë©”íƒ€ì •ë³´
â”‚
â”œâ”€â”€ logs/                        # ğŸ“Š í•™ìŠµ ë¡œê·¸ (ìƒì„±ë¨)
â”‚   â”œâ”€â”€ generation_samples/      #    step_00005.txt ë“± ìƒì„± ìƒ˜í”Œ ê¸°ë¡
â”‚   â””â”€â”€ tensorboard_qwen2.5-3B_* #    TensorBoard ë¡œê·¸ íŒŒì¼
â”‚
â”œâ”€â”€ checkpoints/                 # ğŸ’¾ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (ìƒì„±ë¨)
â”‚   â””â”€â”€ qwen2.5-3B/              #    í•™ìŠµëœ ëª¨ë¸ ì €ì¥
â”‚       â”œâ”€â”€ checkpoint-1000/     #    ê¸°ë³¸ ì €ì¥ ì£¼ê¸°(1000 step)
â”‚       â””â”€â”€ ...                  #    save_stepsë§ˆë‹¤ ìë™ ì €ì¥
```

### ì£¼ìš” íŒŒì¼ ì„¤ëª…

**ì„¤ì • íŒŒì¼**:
- `training_config.yaml`: ëª¨ë“  í•™ìŠµ íŒŒë¼ë¯¸í„° (ëª¨ë¸, ë°°ì¹˜, GRPO, ë³´ìƒ ë“±)

**í•µì‹¬ ìŠ¤í¬ë¦½íŠ¸**:
- `dataset_prep.py`: Countdown ë°ì´í„°ë¥¼ R1 í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
- `rewards.py`: í˜•ì‹/ìˆ˜ì‹/ê¸¸ì´ ë³´ìƒ ë° ì•ˆì „í•œ ìˆ˜ì‹ í‰ê°€ êµ¬í˜„
- `train_grpo.py`: ê°€ì¤‘ì¹˜ ë³´ìƒ ê¸°ë°˜ GRPO í•™ìŠµ ë£¨í”„ + ìƒì„± ìƒ˜í”Œ ë¡œê¹…
- `evaluate.py`: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

**ìƒì„±ë˜ëŠ” ë””ë ‰í† ë¦¬**:
- `.cache/datasets/`: ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ (~50MB)
- `logs/generation_samples/`: í•™ìŠµ ì¤‘ ìƒì„±ëœ í…ìŠ¤íŠ¸ & ë³´ìƒ ë¡œê·¸
- `logs/tensorboard_*`: TensorBoard ì‹œê°í™” ë°ì´í„°
- `checkpoints/`: ëª¨ë¸/LoRA ì²´í¬í¬ì¸íŠ¸ (ê° ~3GB)

## ğŸ§® Reward ì‹œìŠ¤í…œ í•œëˆˆì— ë³´ê¸°

- **Format Reward (ìµœëŒ€ 0.5)**: `<think>...</think><answer>...</answer>` íƒœê·¸ êµ¬ì¡°ë¥¼ ê²€ì¦í•˜ê³  ìˆœì„œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
- **Equation Reward (ìµœëŒ€ 2.0)**: `<answer>` ë‚´ë¶€ ìˆ˜ì‹ì„ `safe_eval`ë¡œ ê³„ì‚°í•´ ì •ë‹µ ì¼ì¹˜ ì—¬ë¶€ì™€ ìˆ«ì ì‚¬ìš© ì •í™•ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
- **Length Penalty (ìµœì†Œ -0.5)**: ìƒì„± ê¸¸ì´ê°€ `max_completion_length` ê·¼ì²˜ë¥¼ ì´ˆê³¼í•˜ë©´ í˜ë„í‹°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
- **ê°€ì¤‘ì¹˜ ì„¤ì •**: `configs/training_config.yaml`ì˜ `reward_weights`ì—ì„œ ê° ë³´ìƒ í•­ëª©ì˜ ì˜í–¥ë ¥ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ìƒ˜í”Œ ë¡œê¹…**: `logs/generation_samples/step_*.txt`ì— ì›ì‹œ/ê°€ì¤‘ì¹˜ ë³´ìƒ ê°’ì´ ëª¨ë‘ ê¸°ë¡ë©ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

### ğŸ® RunPod êµ¬ë™ ì „ì²´ ê³¼ì •

#### 1ï¸âƒ£ Pod ìƒì„± ë° ì ‘ì†
```bash
# RunPodì—ì„œ RTX 4090/A5000 ì„ íƒ
# í…œí”Œë¦¿: PyTorch 2.4 + CUDA 12.1
# ë³¼ë¥¨: ìµœì†Œ 50GB
# Web Terminal ë˜ëŠ” SSHë¡œ ì ‘ì†
```

#### 2ï¸âƒ£ í”„ë¡œì íŠ¸ í´ë¡ 
```bash
cd /workspace
git clone https://github.com/sogmgm/MiniR1_sogmgm_ver.git
cd MiniR1_sogmgm_ver
```

#### 3ï¸âƒ£ í™˜ê²½ ì„¤ì • (5-10ë¶„ ì†Œìš”)
```bash
# UV ì„¤ì¹˜ ë° í™˜ê²½ ë¡œë“œ
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.local/bin/env

# ì˜ì¡´ì„± ì„¤ì¹˜ (í”„ë¡œì íŠ¸ ë¹Œë“œ ì œì™¸)
uv sync --no-install-project

# PyTorch CUDA í™•ì¸ (RunPod pytorch í…œí”Œë¦¿ ì‚¬ìš© ì‹œ ì´ë¯¸ ì„¤ì¹˜ë¨)
uv run python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"

# âŒ "False" ë˜ëŠ” CPU ë²„ì „ì´ë©´ â†’ CUDA ë²„ì „ ì„¤ì¹˜
# uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Flash Attention ì„¤ì¹˜ (ì„ íƒ, 20% ì†ë„ í–¥ìƒ)
uv pip install flash-attn --no-build-isolation
```

> ğŸ’¡ **Tip**: RunPod pytorch í…œí”Œë¦¿ì„ ì‚¬ìš©í–ˆë‹¤ë©´ PyTorch CUDAê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

#### 4ï¸âƒ£ Hugging Face ì¸ì¦
```bash
uv run huggingface-cli login

# ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •
export HF_TOKEN="your_hf_token_here"
```

#### 5ï¸âƒ£ GPU í™•ì¸
```bash
# GPU ìƒíƒœ í™•ì¸
nvidia-smi

# PyTorch CUDA í™•ì¸
uv run python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
```

#### 6ï¸âƒ£ ë°ì´í„°ì…‹ ì¤€ë¹„ (~2-3ë¶„)
```bash
uv run python scripts/dataset_prep.py --config configs/training_config.yaml
# --num_samples 5000 ì²˜ëŸ¼ ì¸ìë¥¼ ì£¼ë©´ ì„¤ì •ê°’ì„ ë®ì–´ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ê¸°ë³¸ ì„¤ì • ê²°ê³¼: train 3,600 / test 400 ìƒ˜í”Œ ìƒì„±
```

#### 7ï¸âƒ£ í•™ìŠµ ì‹œì‘ (10-12ì‹œê°„ ì†Œìš”, A100 80GB ê¸°ì¤€)
```bash
# ë‹¨ì¼ GPU í•™ìŠµ
uv run python scripts/train_grpo.py --config configs/training_config.yaml

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ê¶Œì¥)
nohup uv run python scripts/train_grpo.py --config configs/training_config.yaml > training.log 2>&1 &

# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f training.log

# ìƒì„± ìƒ˜í”Œì€ logs/generation_samples/step_*.txt ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
```

#### 8ï¸âƒ£ TensorBoard ëª¨ë‹ˆí„°ë§ (ì„ íƒ)
```bash
# ë³„ë„ í„°ë¯¸ë„ì—ì„œ
tensorboard --logdir=logs/tensorboard_qwen2.5-3B_25112 --host=0.0.0.0 --port=6006
# ë˜ëŠ” ë¡œê·¸ ë””ë ‰í† ë¦¬ì— ë§ì¶° íŒ¨í„´ ì‚¬ìš© (ì˜ˆ: logs/tensorboard_qwen2.5-3B_*)

# RunPod í¬íŠ¸ í¬ì›Œë”© ì„¤ì • í›„
# ë¸Œë¼ìš°ì €ì—ì„œ: http://localhost:6006
```


#### ì£¼ìš” ë©”íŠ¸ë¦­
```
ğŸ“ˆ train/loss              - í•™ìŠµ ì†ì‹¤ (ê°ì†Œ ì¶”ì„¸ í™•ì¸)
ğŸ“ˆ train/rewards/format    - í¬ë§· ë³´ìƒ 
ğŸ“ˆ train/rewards/equation  - ìˆ˜ì‹ ë³´ìƒ 
ğŸ“ˆ train/rewards/length    - ê¸¸ì´ í˜ë„í‹° ê°ì‹œ 
ğŸ“ˆ train/learning_rate     - í•™ìŠµë¥  (Cosine ê°ì†Œ)
```


### 4ï¸âƒ£ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
```bash
# ì €ì¥ ìœ„ì¹˜ (save_steps: 1000)
checkpoints/qwen2.5-3B/
â”œâ”€â”€ checkpoint-1000/
â”œâ”€â”€ checkpoint-2000/
â””â”€â”€ ...

# save_total_limit ì„¤ì •ì— ë”°ë¼ ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ìë™ ì •ë¦¬
```


### ì™¸ë¶€ ì°¸ê³ ìë£Œ
- **[ì›ë³¸ íŠœí† ë¦¬ì–¼](https://www.philschmid.de/mini-deepseek-r1)**: Philipp Schmidì˜ Mini-DeepSeek R1 ê°€ì´ë“œ
- **[DeepSeek R1 ë…¼ë¬¸](https://arxiv.org/abs/2501.12948)**: ì›ë³¸ ì—°êµ¬ ë…¼ë¬¸
- **[GRPO ë…¼ë¬¸](https://arxiv.org/abs/2402.03300)**: Group Relative Policy Optimization
- **[TRL Documentation](https://huggingface.co/docs/trl)**: Hugging Face TRL ë¼ì´ë¸ŒëŸ¬ë¦¬
- **[Qwen 2.5 ëª¨ë¸](https://huggingface.co/Qwen)**: Qwen ëª¨ë¸ ì¹´ë“œ
- **[UV íŒ¨í‚¤ì§€ ê´€ë¦¬ì](https://github.com/astral-sh/uv)**: UV ê³µì‹ ë¬¸ì„œ

### ê´€ë ¨ í”„ë¡œì íŠ¸
- **[DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)**: ì›ë³¸ DeepSeek R1
- **[OpenAI O1](https://openai.com/o1/)**: ì¶”ë¡  ëª¨ë¸ ë¹„êµ
- **[Countdown Dataset](https://huggingface.co/datasets/Jiayi-Pan/Countdown-Tasks-3to4)**: ì‚¬ìš©í•œ ë°ì´í„°ì…‹

## ğŸ¤ ê¸°ì—¬ ë° ë¼ì´ì„ ìŠ¤

### ê¸°ì—¬ ë°©ë²•
```bash
# 1. Fork í›„ Clone
git clone https://github.com/YOUR_USERNAME/MiniR1.git

# 2. ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/your-feature

```

