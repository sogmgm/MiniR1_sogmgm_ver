# RunPod ì‹¤í–‰ ê°€ì´ë“œ

> Mini-R1 í”„ë¡œì íŠ¸ë¥¼ RunPodì—ì„œ **ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰**í•˜ê¸° ìœ„í•œ ê°€ì´ë“œ

---

## ğŸ® Step 1: GPU ì„ íƒ

### ğŸ’° ì¶”ì²œ GPU (ê°€ì„±ë¹„ + ì„±ëŠ¥)

| GPU | VRAM | ì‹œê°„ë‹¹ ë¹„ìš© | Qwen 1.5B | Qwen 3B | 200 Steps ì˜ˆìƒ ì‹œê°„ | ì´ ì˜ˆìƒ ë¹„ìš© |
|-----|------|------------|-----------|---------|-------------------|-------------|
| **RTX 4090** â­ | 24GB | ~$0.69 | âœ… ìµœì  | âœ… ìµœì  | 3-4ì‹œê°„ | ~$2.50 |
| **RTX A5000** | 24GB | ~$0.50 | âœ… ìµœì  | âœ… ìµœì  | 4-6ì‹œê°„ | ~$2.50 |
| **RTX 3090** | 24GB | ~$0.44 | âœ… ì¢‹ìŒ | âœ… ì¢‹ìŒ | 5-7ì‹œê°„ | ~$2.50 |
| **L4** | 24GB | ~$0.45 | âœ… ê°€ëŠ¥ | âœ… ê°€ëŠ¥ | 6-8ì‹œê°„ | ~$3.00 |

**ìµœì¢… ì¶”ì²œ**: 
- **ê°€ì„±ë¹„ ìµœê³ **: RTX 3090
- **ì†ë„ ìµœìš°ì„ **: RTX 4090
- **ì•ˆì •ì„±**: RTX A5000

### ï¿½ ëª¨ë¸ ì„ íƒ

- **Qwen2.5-1.5B** (ì¶”ì²œ â­)
  - VRAM: ~12-14GB
  - ë¹ ë¥¸ í•™ìŠµ ì†ë„
  - ì €ë ´í•œ ë¹„ìš©
  - ì²« ì‹¤í—˜ì— ìµœì 
  
- **Qwen2.5-3B**
  - VRAM: ~14-18GB
  - ë” ë‚˜ì€ ì¶”ë¡  ì„±ëŠ¥
  - ì•½ê°„ ëŠë¦° ì†ë„
  - VRAM 16GB+ ê¶Œì¥

---

## ğŸš€ Step 2: RunPod Pod ìƒì„±

1. [RunPod](https://www.runpod.io/) ë¡œê·¸ì¸
2. **Community Cloud** ë˜ëŠ” **Secure Cloud** ì„ íƒ
3. ìœ„ì—ì„œ ì„ íƒí•œ GPU ì°¾ê¸°
4. **í…œí”Œë¦¿**: `RunPod PyTorch 2.4` ë˜ëŠ” `CUDA 12.1` í¬í•¨ëœ ê²ƒ
5. **ë³¼ë¥¨**: ìµœì†Œ 30GB (50GB ê¶Œì¥)
6. **Deploy** í´ë¦­!
7. SSH ë˜ëŠ” **Web Terminal** ì ‘ì†

---

## ğŸ“¦ Step 3: í”„ë¡œì íŠ¸ ì—…ë¡œë“œ

### ë°©ë²• 1: GitHub (ì¶”ì²œ)
```bash
cd /workspace
git clone https://github.com/YOUR_USERNAME/MiniR1.git
cd MiniR1
```

### ë°©ë²• 2: ì§ì ‘ ì—…ë¡œë“œ
```bash
# ë¡œì»¬ì—ì„œ
cd /Users/kb.yang/Desktop/kb/repo
tar -czf minir1.tar.gz MiniR1/

# RunPod íŒŒì¼ ë¸Œë¼ìš°ì €ë¡œ ì—…ë¡œë“œ í›„
cd /workspace
tar -xzf minir1.tar.gz
cd MiniR1
```

---

## ğŸ› ï¸ Step 4: UV ë° í™˜ê²½ ì„¤ì •

### 4-1. UV ì„¤ì¹˜
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.cargo/env
uv --version
```

### 4-2. PyTorch ì„¤ì¹˜ (CUDA 12.1)
```bash
uv add torch torchvision torchaudio --index https://download.pytorch.org/whl/cu121
```

### 4-3. í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ë™ê¸°í™”
```bash
uv sync
```

### 4-4. Flash Attention ì„¤ì¹˜ (ì„ íƒ, ì†ë„ 20% í–¥ìƒ)
```bash
uv add flash-attn --no-build-isolation
```
> âš ï¸ ì‹¤íŒ¨í•´ë„ ê´œì°®ìŒ. ì—†ìœ¼ë©´ ì¡°ê¸ˆ ëŠë¦´ ë¿.

### 4-5. HuggingFace ë¡œê·¸ì¸
```bash
# í† í° ì—†ìœ¼ë©´: https://huggingface.co/settings/tokens
uv run huggingface-cli login
```

---

## âœ… Step 5: í™˜ê²½ ê²€ì¦

```bash
uv run python scripts/check_environment.py
```

ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ í™•ì¸:
- âœ… GPU ë° VRAM
- âœ… CUDA ë²„ì „
- âœ… ë””ìŠ¤í¬ ê³µê°„
- âœ… RAM
- âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì—¬ë¶€
- ğŸ’¡ ìµœì  config ì¶”ì²œ

---

## ğŸ“Š Step 6: ë°ì´í„°ì…‹ ì¤€ë¹„

```bash
uv run python scripts/dataset_prep.py --num_samples 5000
```

**ì˜ˆìƒ ì‹œê°„**: 2-5ë¶„  
**ìƒì„± íŒŒì¼**:
- `.cache/datasets/train_countdown_r1.json` (4500ê°œ)
- `.cache/datasets/test_countdown_r1.json` (500ê°œ)

---

## ğŸ§ª Step 7: ë³´ìƒ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸

```bash
uv run python scripts/rewards.py
```

**ì˜ˆìƒ ê²°ê³¼**: ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ âœ…

---

## ğŸ¯ Step 8: ëª¨ë¸ ì„¤ì • (í•„ìš”ì‹œ ìˆ˜ì •)

### 8-1. ëª¨ë¸ ì„ íƒ
```bash
nano configs/training_config.yaml
```

**Qwen 1.5B ì‚¬ìš©** (ì¶”ì²œ):
```yaml
model:
  name: "Qwen/Qwen2.5-1.5B-Instruct"
```

**Qwen 3B ì‚¬ìš©** (VRAM 18GB+ í•„ìš”):
```yaml
model:
  name: "Qwen/Qwen2.5-3B-Instruct"
```

### 8-2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±í•˜ë©´
```yaml
grpo:
  max_completion_length: 384  # 512 â†’ 384
  num_generations: 1          # 2 â†’ 1

training:
  gradient_accumulation_steps: 16  # 8 â†’ 16
```

---

## ğŸš€ Step 9: í•™ìŠµ ì‹œì‘!

```bash
uv run python scripts/train_grpo.py --config configs/training_config.yaml
```

**ì˜ˆìƒ ì‹œê°„**: 
- RTX 4090: 3-4ì‹œê°„
- RTX 3090: 5-7ì‹œê°„
- L4: 6-8ì‹œê°„

**ì²´í¬í¬ì¸íŠ¸ ì €ì¥**: 50, 100, 150, 200 steps

---

## ï¿½ Step 10: ëª¨ë‹ˆí„°ë§ (í•™ìŠµ ì¤‘)

### í„°ë¯¸ë„ 1: í•™ìŠµ ë¡œê·¸
## ğŸ“ˆ Step 10: ëª¨ë‹ˆí„°ë§ (í•™ìŠµ ì¤‘)

### í„°ë¯¸ë„ 1: TensorBoard ì‹¤í–‰ (ì„ íƒ)
```bash
# TensorBoard ì‹œì‘
tensorboard --logdir=logs/tensorboard --host=0.0.0.0 --port=6006
```
**ì ‘ì†**: RunPodì˜ í¬íŠ¸ í¬ì›Œë”© ë˜ëŠ” `http://localhost:6006`

### í„°ë¯¸ë„ 2: í•™ìŠµ ì§„í–‰ìƒí™© í™•ì¸
```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ë³´ê¸°
tail -f logs/training.log
```

### í„°ë¯¸ë„ 3: GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
```bash
# 1ì´ˆë§ˆë‹¤ GPU ìƒíƒœ í™•ì¸
watch -n 1 nvidia-smi
```

### ìƒì„± ìƒ˜í”Œ í™•ì¸
```bash
# Step 50 ìƒ˜í”Œ
cat completion_samples/step_0050_success.txt

# Step 100 ìƒ˜í”Œ
cat completion_samples/step_0100_success.txt
```

### TensorBoardì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­
- **Loss**: í•™ìŠµ ì†ì‹¤
- **Learning Rate**: í•™ìŠµë¥  ë³€í™”
- **Rewards**: ë³´ìƒ ì ìˆ˜ ë³€í™”
- **GPU Utilization**: GPU ì‚¬ìš©ë¥ 

> ğŸ’¡ TensorBoardëŠ” 25 stepë§ˆë‹¤ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤ (ë©”ëª¨ë¦¬ ì ˆì•½)

---

## ğŸ“ Step 11: í•™ìŠµ ì™„ë£Œ í›„

### ê²°ê³¼ í™•ì¸
```bash
# ì§„í–‰ ìƒí™© ë³´ê¸°
cat PROGRESS.md

# ì²´í¬í¬ì¸íŠ¸ í™•ì¸
ls -lh checkpoints/qwen-r1-countdown/
```

### ìµœì¢… ëª¨ë¸ í‰ê°€
```bash
uv run python scripts/evaluate.py --checkpoint checkpoints/qwen-r1-countdown/checkpoint-200
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### âŒ CUDA Out of Memory
**ì¦ìƒ**: RuntimeError: CUDA out of memory

**í•´ê²°ì±…**:
```bash
# configs/training_config.yaml ìˆ˜ì •
nano configs/training_config.yaml
```

```yaml
# 1.5Bë¡œ ë³€ê²½
model:
  name: "Qwen/Qwen2.5-1.5B-Instruct"

# ì‹œí€€ìŠ¤ ê¸¸ì´ ì¶•ì†Œ
grpo:
  max_completion_length: 384
  num_generations: 1

# Gradient accumulation ì¦ê°€
training:
  gradient_accumulation_steps: 16
```

### âŒ í•™ìŠµ ì¤‘ë‹¨ë˜ì—ˆì„ ë•Œ
```bash
# ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
uv run python scripts/train_grpo.py \
  --config configs/training_config.yaml \
  --resume_from_checkpoint checkpoints/qwen-r1-countdown/checkpoint-100
```

### âŒ Flash Attention ì„¤ì¹˜ ì‹¤íŒ¨
```bash
# configs/training_config.yaml ìˆ˜ì •
nano configs/training_config.yaml
```

```yaml
model:
  attn_implementation: "eager"  # flash_attention_2 â†’ eager
```

### âŒ UV ì„¤ì¹˜ ì‹¤íŒ¨
```bash
# ëŒ€ì²´: pip ì‚¬ìš©
python -m venv .venv
source .venv/bin/activate
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -e .
```

### âŒ Disk Space ë¶€ì¡±
```bash
# ë°ì´í„°ì…‹ ìƒ˜í”Œ ì¤„ì´ê¸°
uv run python scripts/dataset_prep.py --num_samples 2000

# ì²´í¬í¬ì¸íŠ¸ ê°œìˆ˜ ì¤„ì´ê¸°
# configs/training_config.yamlì—ì„œ
training:
  save_total_limit: 2  # 4 â†’ 2
```

---

## ğŸ’¡ íŒê³¼ íŠ¸ë¦­

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (10 stepsë§Œ)
```bash
uv run python scripts/train_grpo.py \
  --config configs/training_config.yaml \
  --max_steps 10
```

### GPU í™œìš©ë¥  ìµœëŒ€í™”
```yaml
# ë©”ëª¨ë¦¬ ì—¬ìœ  ìˆìœ¼ë©´
training:
  per_device_train_batch_size: 2  # 1 â†’ 2
  gradient_accumulation_steps: 4   # 8 â†’ 4
```

### ë” ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í—˜
```bash
uv run python scripts/dataset_prep.py --num_samples 1000
```

### í•™ìŠµ ì¤‘ ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ ìƒ˜í”Œ ìƒì„± (TODO)
```bash
uv run python scripts/generate_samples.py --checkpoint checkpoints/qwen-r1-countdown/checkpoint-100
```

---

## ï¿½ ì˜ˆìƒ ê²°ê³¼

### í•™ìŠµ ì§„í–‰ (200 Steps)
| Step | Format ì •í™•ë„ | ì •ë‹µë¥  | íŠ¹ì§• |
|------|--------------|--------|------|
| 50   | ~90% | ~5% | `<think></think><answer></answer>` í•™ìŠµ ì™„ë£Œ |
| 100  | ~95% | ~15-20% | ê°„ë‹¨í•œ ê³„ì‚° ì‹œì‘ |
| 150  | ~95% | ~25-30% | ì—°ì‚° ì¡°í•© ì‹œë„ |
| 200  | ~95% | ~35-40% | ë³µì¡í•œ ì¶”ë¡  íŒ¨í„´ |

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
- **GPU ë©”ëª¨ë¦¬**: 
  - Qwen 1.5B: 12-14GB
  - Qwen 3B: 14-18GB
- **ë””ìŠ¤í¬**: ~10GB
- **RAM**: ~16GB

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤í–‰ ì „ í™•ì¸:

- [ ] GPU ì„ íƒ ì™„ë£Œ (24GB VRAM ê¶Œì¥)
- [ ] RunPod Pod ìƒì„± ë° ì ‘ì†
- [ ] í”„ë¡œì íŠ¸ ì—…ë¡œë“œ (GitHub ë˜ëŠ” ì§ì ‘)
- [ ] UV ì„¤ì¹˜ ë° ê°€ìƒ í™˜ê²½ ìƒì„±
- [ ] PyTorch + ì˜ì¡´ì„± ì„¤ì¹˜
- [ ] HuggingFace ë¡œê·¸ì¸
- [ ] í™˜ê²½ ê²€ì¦ í†µê³¼ (`check_environment.py`)
- [ ] ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ 20GB+
- [ ] ëª¨ë¸ ì„ íƒ (1.5B ë˜ëŠ” 3B)
- [ ] Pod ìë™ ì¢…ë£Œ ë°©ì§€ ì„¤ì •

---

## ğŸ“ ì¶”ê°€ ë„ì›€ë§

**ë¡œê·¸ í™•ì¸**:
```bash
# í•™ìŠµ ë¡œê·¸
cat logs/training.log

# GPU ìƒíƒœ
nvidia-smi

# ì§„í–‰ ìƒí™©
cat PROGRESS.md
```

**íŒŒì¼ êµ¬ì¡°**:
```
MiniR1/
â”œâ”€â”€ checkpoints/           # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚   â””â”€â”€ qwen-r1-countdown/
â”‚       â”œâ”€â”€ checkpoint-50/
â”‚       â”œâ”€â”€ checkpoint-100/
â”‚       â”œâ”€â”€ checkpoint-150/
â”‚       â””â”€â”€ checkpoint-200/
â”œâ”€â”€ completion_samples/    # ìƒì„± ìƒ˜í”Œ
â”œâ”€â”€ logs/                  # í•™ìŠµ ë¡œê·¸
â”œâ”€â”€ .cache/datasets/       # ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹
â””â”€â”€ configs/               # ì„¤ì • íŒŒì¼
```

---

**ì¤€ë¹„ ì™„ë£Œ! Step 4ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”!** ğŸš€
