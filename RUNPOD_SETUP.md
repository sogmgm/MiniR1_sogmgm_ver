# RunPod ì™„ì „ ê°€ì´ë“œ

> Mini-R1 í”„ë¡œì íŠ¸ë¥¼ RunPodì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ **ì™„ë²½ ê°€ì´ë“œ**

---

## âš¡ ë¹ ë¥¸ ì‹œì‘ (5ë¶„ ì„¤ì¹˜)

```bash
# 1. í”„ë¡œì íŠ¸ í´ë¡ 
cd /workspace
git clone https://github.com/sogmgm/MiniR1_sogmgm_ver.git
cd MiniR1_sogmgm_ver

# 2. UV ì„¤ì¹˜ ë° PATH ì„¤ì •
curl -LsSf https://astral.sh/uv/install.sh | sh
export PATH="$HOME/.local/bin:$PATH"
uv --version

# 3. ì˜ì¡´ì„± ì„¤ì¹˜ (í”„ë¡œì íŠ¸ ë¹Œë“œ ì œì™¸)
uv sync --no-install-project

# 4. PyTorch ì„¤ì¹˜ (CUDA 12.1)
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 5. HuggingFace ë¡œê·¸ì¸
export HF_TOKEN="your_token_here"

# 6. í™˜ê²½ í™•ì¸
uv run python scripts/check_environment.py

# 7. ë°ì´í„° ì¤€ë¹„ (2-3ë¶„)
uv run python scripts/dataset_prep.py --num_samples 5000

# 8. í•™ìŠµ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
nohup uv run python scripts/train_grpo.py --config configs/training_config.yaml > training.log 2>&1 &

# 9. ë¡œê·¸ í™•ì¸
tail -f training.log
```

**ì˜ˆìƒ ì´ ì†Œìš” ì‹œê°„**: 
- ì„¤ì¹˜: ~10ë¶„
- ë°ì´í„° ì¤€ë¹„: ~3ë¶„
- í•™ìŠµ (200 steps): 3-4ì‹œê°„ (RTX 4090 ê¸°ì¤€)

---

## ğŸ“‹ ë¹ ë¥¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹œì‘ ì „ í™•ì¸
- [ ] RunPod GPU ì„ íƒ (RTX 4090/A5000 ê¶Œì¥)
- [ ] í…œí”Œë¦¿: `runpod/pytorch:1.0.2-cu1281-torch280-ubuntu2404` ë˜ëŠ” CUDA 12.1+
- [ ] ë³¼ë¥¨: 50GB ì´ìƒ
- [ ] HuggingFace í† í° ì¤€ë¹„

### ì„¤ì¹˜ í›„ í™•ì¸
- [ ] `pwd` â†’ `/workspace/MiniR1_sogmgm_ver`
- [ ] `uv --version` â†’ `uv 0.9.8` ì´ìƒ
- [ ] `ls pyproject.toml` â†’ íŒŒì¼ ì¡´ì¬ í™•ì¸
- [ ] í™˜ê²½ ê²€ì¦ í†µê³¼ (`check_environment.py`)

---

## ğŸ® Step 1: GPU ì„ íƒ

### ğŸ’° ì¶”ì²œ GPU (ê°€ì„±ë¹„ + ì„±ëŠ¥)

| GPU | VRAM | ì‹œê°„ë‹¹ ë¹„ìš© | Qwen 1.5B | Qwen 3B | í•™ìŠµ ì‹œê°„ | ì´ ë¹„ìš© |
|-----|------|------------|-----------|---------|----------|---------|
| **RTX 4090** â­ | 24GB | ~$0.69 | âœ… ìµœì  | âœ… ìµœì  | 3-4ì‹œê°„ | ~$2.50 |
| **RTX A5000** | 24GB | ~$0.50 | âœ… ìµœì  | âœ… ìµœì  | 4-6ì‹œê°„ | ~$2.50 |
| **RTX 3090** | 24GB | ~$0.44 | âœ… ì¢‹ìŒ | âœ… ì¢‹ìŒ | 5-7ì‹œê°„ | ~$2.60 |
| **L4** | 24GB | ~$0.45 | âœ… ê°€ëŠ¥ | âœ… ê°€ëŠ¥ | 6-8ì‹œê°„ | ~$3.00 |

**ìµœì¢… ì¶”ì²œ**: 
- **ê°€ì„±ë¹„ ìµœê³ **: RTX 3090
- **ì†ë„ ìµœìš°ì„ **: RTX 4090
- **ì•ˆì •ì„±**: RTX A5000

### ğŸ’¡ ëª¨ë¸ ì„ íƒ

- **Qwen2.5-1.5B** (ì¶”ì²œ â­)
  - VRAM: ~12-14GB
  - ë¹ ë¥¸ í•™ìŠµ ì†ë„
  - ì²« ì‹¤í—˜ì— ìµœì 
  
- **Qwen2.5-3B**
  - VRAM: ~14-18GB
  - ë” ë‚˜ì€ ì¶”ë¡  ì„±ëŠ¥
  - VRAM 18GB+ ê¶Œì¥

---

## ğŸš€ Step 2: RunPod Pod ìƒì„±

1. [RunPod](https://www.runpod.io/) ë¡œê·¸ì¸
2. **Community Cloud** ë˜ëŠ” **Secure Cloud** ì„ íƒ
3. GPU ì„ íƒ
4. **í…œí”Œë¦¿**: `runpod/pytorch:1.0.2-cu1281-torch280-ubuntu2404` (ê¶Œì¥)
5. **ë³¼ë¥¨**: 50GB ì´ìƒ
6. **Deploy** í´ë¦­
7. SSH ë˜ëŠ” **Web Terminal** ì ‘ì†

---

## ğŸ“¦ Step 3: í”„ë¡œì íŠ¸ í´ë¡ 

```bash
cd /workspace
git clone https://github.com/sogmgm/MiniR1_sogmgm_ver.git
cd MiniR1_sogmgm_ver

# í˜„ì¬ ìœ„ì¹˜ í™•ì¸ (ì¤‘ìš”!)
pwd
# ì¶œë ¥: /workspace/MiniR1_sogmgm_ver
```

---

## ğŸ› ï¸ Step 4: UV ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### 4-1. UV ì„¤ì¹˜ ë° PATH ì„¤ì •
```bash
# UV ì„¤ì¹˜
curl -LsSf https://astral.sh/uv/install.sh | sh

# PATH ì„¤ì • (ì¤‘ìš”!)
export PATH="$HOME/.local/bin:$PATH"

# ë˜ëŠ” (ì„¤ì¹˜ ìœ„ì¹˜ì— ë”°ë¼)
source $HOME/.local/bin/env

# ë²„ì „ í™•ì¸
uv --version
```

### 4-2. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ í™•ì¸
```bash
# ë°˜ë“œì‹œ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•¨
pwd
# /workspace/MiniR1_sogmgm_ver

# pyproject.toml í™•ì¸
ls -la pyproject.toml
```

### 4-3. ì˜ì¡´ì„± ì„¤ì¹˜ (í”„ë¡œì íŠ¸ ë¹Œë“œ ì œì™¸)
```bash
# ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜ (ê¶Œì¥, ë¹ ë¦„)
uv sync --no-install-project
```

### 4-4. PyTorch ì„¤ì¹˜ (CUDA 12.1)
```bash
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 4-5. Flash Attention ì„¤ì¹˜ (ì„ íƒ)
```bash
# ì†ë„ 20% í–¥ìƒ, í•˜ì§€ë§Œ 5-10ë¶„ ì†Œìš”
uv pip install flash-attn --no-build-isolation
```
> âš ï¸ ì‹¤íŒ¨í•´ë„ ê´œì°®ìŒ. ì—†ìœ¼ë©´ ì¡°ê¸ˆ ëŠë¦´ ë¿ì…ë‹ˆë‹¤.

### 4-6. HuggingFace ë¡œê·¸ì¸
```bash
# ë°©ë²• 1: í† í°ìœ¼ë¡œ (ê¶Œì¥)
export HF_TOKEN="your_token_here"

# ë°©ë²• 2: ëŒ€í™”í˜•
uv run huggingface-cli login
```

**í† í° ë°œê¸‰**: https://huggingface.co/settings/tokens

---

## âœ… Step 5: í™˜ê²½ ê²€ì¦

```bash
uv run python scripts/check_environment.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```
âœ… GPU: NVIDIA GeForce RTX 4090
âœ… VRAM: 24.0 GB
âœ… CUDA: 12.1
âœ… PyTorch: 2.5.0+cu121
âœ… All dependencies installed
```

---

## ğŸ“Š Step 6: ë°ì´í„°ì…‹ ì¤€ë¹„

```bash
# ê¸°ë³¸ 5,000 ìƒ˜í”Œ (ì¶”ì²œ)
uv run python scripts/dataset_prep.py --num_samples 5000

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
uv run python scripts/dataset_prep.py --num_samples 1000

# ê¸´ í•™ìŠµìš©
uv run python scripts/dataset_prep.py --num_samples 10000
```

**ì˜ˆìƒ ì‹œê°„**: 2-5ë¶„  
**ìƒì„± íŒŒì¼**:
- `.cache/datasets/train_countdown_r1.json`
- `.cache/datasets/test_countdown_r1.json`

---

## ğŸ¯ Step 7: ëª¨ë¸ ì„¤ì • (ì„ íƒ)

```bash
nano configs/training_config.yaml
```

### ëª¨ë¸ ì„ íƒ
```yaml
# Qwen 1.5B (ì¶”ì²œ)
model:
  name: "Qwen/Qwen2.5-1.5B-Instruct"

# Qwen 3B (VRAM 18GB+ í•„ìš”)
model:
  name: "Qwen/Qwen2.5-3B-Instruct"
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
```yaml
grpo:
  max_completion_length: 256  # 512 â†’ 256
  num_generations: 1          # 2 â†’ 1

training:
  gradient_accumulation_steps: 8  # 4 â†’ 8
```

---

## ğŸš€ Step 8: í•™ìŠµ ì‹œì‘!

### ë°©ë²• 1: ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ê¶Œì¥)
```bash
nohup uv run python scripts/train_grpo.py \
  --config configs/training_config.yaml \
  > training.log 2>&1 &

# ë¡œê·¸ í™•ì¸
tail -f training.log
```

### ë°©ë²• 2: tmux ì‚¬ìš©
```bash
# ì„¸ì…˜ ìƒì„±
tmux new -s training

# í•™ìŠµ ì‹¤í–‰
uv run python scripts/train_grpo.py --config configs/training_config.yaml

# ë‚˜ê°€ê¸°: Ctrl+B, D
# ì¬ì ‘ì†: tmux attach -t training
```

### ë°©ë²• 3: í¬ê·¸ë¼ìš´ë“œ
```bash
uv run python scripts/train_grpo.py --config configs/training_config.yaml
```

---

## ğŸ“ˆ Step 9: ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ë¡œê·¸
```bash
tail -f training.log
```

### TensorBoard (ì„ íƒ)
```bash
# ë³„ë„ í„°ë¯¸ë„ì—ì„œ
tensorboard --logdir=logs/tensorboard --host=0.0.0.0 --port=6006
```

**RunPod í¬íŠ¸ ì—°ê²°**:
1. RunPod UI â†’ Pod í´ë¦­ â†’ "Connect"
2. "TCP Port Mappings" â†’ Port 6006 ì¶”ê°€
3. ìƒì„±ëœ URL ì ‘ì†

### GPU ëª¨ë‹ˆí„°ë§
```bash
watch -n 1 nvidia-smi
```

### ìƒì„± ìƒ˜í”Œ í™•ì¸
```bash
ls -lh completion_samples/
cat completion_samples/step_0050_success.txt
cat completion_samples/step_0100_success.txt
```

---

## ğŸ“ Step 10: í‰ê°€

```bash
# ìµœì¢… í‰ê°€
uv run python scripts/evaluate.py \
  --checkpoint checkpoints/qwen-r1-countdown/checkpoint-200 \
  --num_samples 100

# íŠ¹ì • ì²´í¬í¬ì¸íŠ¸
uv run python scripts/evaluate.py \
  --checkpoint checkpoints/qwen-r1-countdown/checkpoint-100 \
  --num_samples 50
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### âŒ UV ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
```bash
export PATH="$HOME/.local/bin:$PATH"
# ë˜ëŠ”
source $HOME/.local/bin/env

# ì˜êµ¬ ì„¤ì •
echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc
```

### âŒ pyproject.tomlì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /workspace/MiniR1_sogmgm_ver
pwd
ls -la pyproject.toml
```

### âŒ CUDA Out of Memory
```yaml
# configs/training_config.yaml ìˆ˜ì •
model:
  name: "Qwen/Qwen2.5-1.5B-Instruct"  # 3B â†’ 1.5B

grpo:
  max_completion_length: 256
  num_generations: 1

training:
  gradient_accumulation_steps: 8
```

### âŒ í•™ìŠµ ì¤‘ë‹¨ í›„ ì¬ê°œ
```bash
uv run python scripts/train_grpo.py \
  --config configs/training_config.yaml \
  --resume_from_checkpoint checkpoints/qwen-r1-countdown/checkpoint-100
```

### âŒ Flash Attention ì„¤ì¹˜ ì‹¤íŒ¨
```bash
# ë¬´ì‹œí•˜ê³  ì§„í–‰ (ì„ íƒì‚¬í•­ì´ë¯€ë¡œ OK)

# ë˜ëŠ” ì„¤ì •ì—ì„œ ë¹„í™œì„±í™”
nano configs/training_config.yaml
```

```yaml
model:
  attn_implementation: "eager"  # flash_attention_2 â†’ eager
```

---

## ğŸ’¡ ìœ ìš©í•œ íŒ

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (10 steps)
```bash
uv run python scripts/train_grpo.py \
  --config configs/training_config.yaml \
  --max_steps 10
```

### í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬
```bash
# í™•ì¸
ps aux | grep train_grpo

# ì¢…ë£Œ
pkill -f train_grpo
```

### ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
```bash
df -h /workspace
```

---

## ï¿½ ì˜ˆìƒ ê²°ê³¼

### í•™ìŠµ ì§„í–‰ (200 Steps)

| Step | Format ì •í™•ë„ | ì •ë‹µë¥  | íŠ¹ì§• |
|------|--------------|--------|------|
| 50   | ~90% | ~5% | í˜•ì‹ í•™ìŠµ ì™„ë£Œ |
| 100  | ~95% | ~15-20% | ì´ˆê¸° ì¶”ë¡  ì‹œì‘ |
| 150  | ~95% | ~25-30% | íŒ¨í„´ ì¸ì‹ |
| 200  | ~95% | ~35-40% | ì•ˆì •ì  ì¶”ë¡  |

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

- **GPU ë©”ëª¨ë¦¬**: 
  - Qwen 1.5B: 12-14GB
  - Qwen 3B: 14-18GB
- **ë””ìŠ¤í¬**: ~10GB
- **RAM**: ~16GB

---

## ğŸ“Š í•µì‹¬ ê°œë…

### ë°ì´í„° í˜•íƒœ
```
ì…ë ¥: {nums: [19,36,55,7], target: 65}
  â†“
í”„ë¡¬í”„íŠ¸: "Using [19,36,55,7], make 65. <think>"
  â†“
ëª¨ë¸ ì¶œë ¥: "ì¶”ë¡ ... </think>\n<answer>55+36-7-19</answer>"
  â†“
ë³´ìƒ: Format(1.0) + Equation(1.0) = 2.0
```

### í•™ìŠµ ì§„í–‰
- **0-50 steps**: í˜•ì‹ í•™ìŠµ (`<think></think>` êµ¬ì¡°)
- **50-100 steps**: ì´ˆê¸° ì¶”ë¡  (ê°„ë‹¨í•œ ê³„ì‚°)
- **100-150 steps**: íŒ¨í„´ ì¸ì‹ (ìˆ«ì ì¡°í•©)
- **150-200 steps**: ì„±ëŠ¥ ìˆ˜ë ´ (ì•ˆì •ì  ì¶”ë¡ )

---

## ğŸ”— ë” ì•Œì•„ë³´ê¸°

- **ì „ì²´ ê°€ì´ë“œ**: [README.md](README.md)
- **TensorBoard**: [TENSORBOARD_GUIDE.md](TENSORBOARD_GUIDE.md)
- **ì§„í–‰ ìƒí™©**: [PROGRESS.md](PROGRESS.md)

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] GPU ì„ íƒ ë° Pod ìƒì„±
- [ ] í”„ë¡œì íŠ¸ í´ë¡ 
- [ ] UV ì„¤ì¹˜ ë° PATH ì„¤ì •
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜ (`uv sync --no-install-project`)
- [ ] PyTorch ì„¤ì¹˜
- [ ] HuggingFace ë¡œê·¸ì¸
- [ ] í™˜ê²½ ê²€ì¦
- [ ] ë°ì´í„° ì¤€ë¹„
- [ ] í•™ìŠµ ì‹œì‘
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì •

---

**ğŸš€ ëª¨ë“  ì¤€ë¹„ ì™„ë£Œ! í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”!**

**ì˜ˆìƒ ì´ ë¹„ìš©**: ~$2.50 (RTX 4090, 200 steps ê¸°ì¤€)
